### Hi there, I'm Vitaly ðŸ‘‹

I am a **Senior ML Engineer** focused on building autonomous AI systems and high-load inference pipelines. I specialize in bridging the gap between Data Science research and robust production engineering.

Currently, I'm diving deep into **Agentic Workflows (LangGraph)** and **Enterprise RAG**.

---

### ðŸ›  Tech Stack

*   **LLM & GenAI:** LangChain, LangGraph, vLLM, OpenAI API, HuggingFace.
*   **Inference & MLOps:** **Triton Inference Server**, Docker, Kubernetes, FastAPI, ONNX, TensorRT.
*   **Computer Vision:** YOLO, OpenCV, PyTorch.
*   **Data Engineering:** PostgreSQL, ClickHouse, Vector Databases (Milvus/Qdrant/FAISS).

---

### ðŸš€ Featured Projects

#### ðŸ¤– [Autonomous Social Media Agents](https://github.com/pueraeternis/autonomous-content-agents)
*A multi-agent system based on **LangGraph** & **vLLM** that automates content creation.*
*   **Core:** Orchestrates 5+ AI agents (Collector, Editor, Publisher) to generate high-quality articles.
*   **Tech:** Python, LangGraph, Docker, Local LLM Inference.

#### ðŸ”’ [Enterprise RAG Suite](https://github.com/pueraeternis/secure-enterprise-rag)
*Self-hosted Knowledge Base Assistant with focus on data privacy.*
*   **Features:** Multi-modal support, hybrid search (dense + sparse), strict role-based access.
*   **Tech:** Open Web UI, Milvus, Mistral.

#### âš¡ [High-Performance Inference with Triton](https://github.com/pueraeternis/triton-inference-deploy)
*Benchmarking and deploying LLMs for high-load environments.*
*   **Result:** Achieved 3x throughput increase compared to standard FastAPI serving.
*   **Tech:** NVIDIA Triton Inference Server, TensorRT, Prometheus (Monitoring).

---

### ðŸ“« Let's Connect

*   **LinkedIn:** [Vitaly Babchuk](https://www.linkedin.com/in/vitaliy-babchuk)
*   **Email:** babchuk.vit@gmail.com
